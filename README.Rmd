---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# RcppStatGen

<!-- badges: start -->
<!-- badges: end -->

RcppStatGen is an R/RcppEigen package with code snippets for Statistical Genetics tasks.


## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("variani/RcppStatGen")
```

# Examples

```{r lib}
library(RcppStatGen)
library(magrittr) # for %>%

eigen_version()
```

Basic example of scaling a numeric matrix.

```{r scale}
iris[, -5]  %>% head %>% as.matrix %>% eigen_scale
```

Example of scaling a matrix with missing data.

```{r scale_missing}
matrix(1:9, 3, 3) %>% eigen_scale_naive
matrix(c(NA, 2:9), 3, 3) %>% eigen_scale_naive
matrix(c(NA, 2:9), 3, 3) %>% eigen_scale
```

# Benchmarks

## Scale matrix

The standard R function `scale` requires ~10x more RAM than its Eigen implementations.
Eigen implementations are also several times faster.

```{r bench_scale}
library(bench)

fun_bench <- function(n = 1e4, p = 1e3)
{
  X <- matrix(rnorm(n*p), n, p)
  bench::mark(scale(X), eigen_scale_naive(X), eigen_scale(X), check = FALSE, relative = TRUE)
}
fun_bench()
```

## Scale matrix in-place

Scaling matrix in-place requires almost no extra RAM (just needed to store means/sds for each column).
Thus, the memory footprint is reduced by a factor of n = 1e4 (the number of rows).

This exercise was motivated by this [SO](https://stackoverflow.com/questions/27935124/is-it-okay-to-modify-a-mapped-matrix-in-rcppeigen) question.
In general, one expects from scaling function to take one input matrix of raw data (to keep untouched) and create another new matrix of per-column scaled data.

```{r bench_scale_inplace}
fun_bench_inplace<- function(n = 1e4, p = 1e3)
{
  X <- matrix(rnorm(n*p), n, p)
  bench::mark(eigen_scale(X), eigen_scale_inplace(X), check = FALSE)
}
fun_bench_inplace()
```

The extra RAM used by `eigen_scale` function (compared to `eigen_scale_inplace`)
is equal to the size of matrix `X` (76Mb).

```{r size_X}
n <- 1e4
p <- 1e3
X <- matrix(rnorm(n*p), n, p)
object.size(X) %>% print(units = "auto")
rm(X)
```

## QR decomposition

- Getting Q matrix from `Eigen::HouseholderQR` needs thinning. [Code example](https://forum.kde.org/viewtopic.php?f=74&t=106635).
  Code `A_ortho = A.householderQr().householderQ();` [link](https://forum.kde.org/viewtopic.php?f=74&t=118568) will return a matrix Q 
  with the number of columns different from the matrix rank.
- [QR Decomposition results in eigen library differs from Matlab](https://math.stackexchange.com/questions/1396308/qr-decomposition-results-in-eigen-library-differs-from-matlab):

> Note that the different underlying matrix packages (LAPACK and Eigen) most likely implement a different type of QR algorithm.

Given an example matrix with 16 columns and two columns, 4 and 16, to retained by QR,
two strategies perform differently.

```{r qr}
data(X16)
dim(X16)
sel
unsel

# 1. QR with pre-selected columns: re-ordering columns fails
try(eigen_qri_keep(X16, sel))

# 2. QR with pre-selected columns: projeced seleced columns from X
eigen_qrp_keep(X16, sel)

# Usual QR 
qr(X16)$rank
```

